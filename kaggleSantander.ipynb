{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d6aaf2</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fbd867</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0027d6b71</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028cbf45</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002a68644</td>\n",
       "      <td>14400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4993 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID      target  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  \\\n",
       "0  000d6aaf2  38000000.0        0.0          0        0.0          0   \n",
       "1  000fbd867    600000.0        0.0          0        0.0          0   \n",
       "2  0027d6b71  10000000.0        0.0          0        0.0          0   \n",
       "3  0028cbf45   2000000.0        0.0          0        0.0          0   \n",
       "4  002a68644  14400000.0        0.0          0        0.0          0   \n",
       "\n",
       "   2f0771a37  30347e683  d08d1fbe3  6ee66e115    ...      3ecc09859  \\\n",
       "0          0          0          0          0    ...            0.0   \n",
       "1          0          0          0          0    ...            0.0   \n",
       "2          0          0          0          0    ...            0.0   \n",
       "3          0          0          0          0    ...            0.0   \n",
       "4          0          0          0          0    ...            0.0   \n",
       "\n",
       "   9281abeea  8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  \\\n",
       "0        0.0        0.0          0          0          0          0   \n",
       "1        0.0        0.0          0          0          0          0   \n",
       "2        0.0        0.0          0          0          0          0   \n",
       "3        0.0        0.0          0          0          0          0   \n",
       "4        0.0        0.0          0          0          0          0   \n",
       "\n",
       "   fb36b89d9  7e293fbaf  9fc776466  \n",
       "0          0          0          0  \n",
       "1          0          0          0  \n",
       "2          0          0          0  \n",
       "3          0          0          0  \n",
       "4          0          0          0  \n",
       "\n",
       "[5 rows x 4993 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000137c73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00021489f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004d7953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00056a333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00056d8eb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4992 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  2f0771a37  \\\n",
       "0  000137c73        0.0        0.0        0.0        0.0        0.0   \n",
       "1  00021489f        0.0        0.0        0.0        0.0        0.0   \n",
       "2  0004d7953        0.0        0.0        0.0        0.0        0.0   \n",
       "3  00056a333        0.0        0.0        0.0        0.0        0.0   \n",
       "4  00056d8eb        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   30347e683  d08d1fbe3  6ee66e115  20aa07010    ...      3ecc09859  \\\n",
       "0        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "1        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "2        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "3        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "4        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "\n",
       "   9281abeea  8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   fb36b89d9  7e293fbaf  9fc776466  \n",
       "0        0.0        0.0        0.0  \n",
       "1        0.0        0.0        0.0  \n",
       "2        0.0        0.0        0.0  \n",
       "3        0.0        0.0        0.0  \n",
       "4        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 4992 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_IDs = df_train['ID']\n",
    "y_train = df_train['target']\n",
    "train_df = df_train.drop(['ID', 'target'], axis=1)\n",
    "\n",
    "test_IDs = df_test['ID']\n",
    "test_df = df_test.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4459\n",
      "Test size: 49342\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size: {}\".format(train_df.shape[0]))\n",
    "print(\"Test size: {}\".format(test_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABB4AAAGCCAYAAABHOgCsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nknpj4kGSJEmSJPXm/wCdxaHMlgKQ3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12925b51e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y_train, bins=50)\n",
    "plt.title('Histogram of target values.')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(np.log(y_train), bins=50)\n",
    "plt.title('Histogram of log of target values.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>missing_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [column_name, missing_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = train_df.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df = missing_df[missing_df['missing_count']>0]\n",
    "missing_df = missing_df.sort_values(by='missing_count')\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>missing_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [column_name, missing_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = test_df.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df = missing_df[missing_df['missing_count']>0]\n",
    "missing_df = missing_df.sort_values(by='missing_count')\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values. However, this could mean that the NaN values were manually removed or imputed before the dataset was provided. For example, 0s might have formerly been missing values. Should check the correlation between the values of different features to make sure of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for constant values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df_train = train_df.nunique().reset_index()\n",
    "unique_df_train.columns = [\"col_name\", \"unique_count\"]\n",
    "constant_df_train = unique_df_train[unique_df_train[\"unique_count\"]==1]\n",
    "constant_df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df_test = test_df.nunique().reset_index()\n",
    "unique_df_test.columns = [\"col_name\", \"unique_count\"]\n",
    "constant_df_test = unique_df_test[unique_df_test[\"unique_count\"]==1]\n",
    "constant_df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(constant_df_train['col_name'].values, axis=1)\n",
    "test_df = test_df.drop(constant_df_train['col_name'].values, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features that are constant in the train set are not necessarily constant in the test set. For now, they are completely removed from both. However, there should be a way to make use of this information somehow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale and normalize the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>dc5a8f1d8</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.465493e+04</td>\n",
       "      <td>1.390895e+03</td>\n",
       "      <td>2.672245e+04</td>\n",
       "      <td>4.530164e+03</td>\n",
       "      <td>2.640996e+04</td>\n",
       "      <td>3.070811e+04</td>\n",
       "      <td>1.686522e+04</td>\n",
       "      <td>4.669208e+03</td>\n",
       "      <td>2.569407e+06</td>\n",
       "      <td>1.552158e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>4.676057e+05</td>\n",
       "      <td>4.446239e+05</td>\n",
       "      <td>8.056219e+05</td>\n",
       "      <td>7.812966e+05</td>\n",
       "      <td>143.529939</td>\n",
       "      <td>1.213809e+05</td>\n",
       "      <td>3.573451e+04</td>\n",
       "      <td>3.123741e+05</td>\n",
       "      <td>9.219960e+04</td>\n",
       "      <td>2.279100e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.893298e+05</td>\n",
       "      <td>6.428302e+04</td>\n",
       "      <td>5.699652e+05</td>\n",
       "      <td>2.359124e+05</td>\n",
       "      <td>1.514730e+06</td>\n",
       "      <td>5.770590e+05</td>\n",
       "      <td>7.512756e+05</td>\n",
       "      <td>1.879449e+05</td>\n",
       "      <td>9.610183e+06</td>\n",
       "      <td>1.587815e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.068038e+06</td>\n",
       "      <td>4.428889e+06</td>\n",
       "      <td>4.513246e+06</td>\n",
       "      <td>6.839451e+06</td>\n",
       "      <td>9584.318507</td>\n",
       "      <td>4.720709e+06</td>\n",
       "      <td>1.614622e+06</td>\n",
       "      <td>4.318501e+06</td>\n",
       "      <td>1.635993e+06</td>\n",
       "      <td>1.811139e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>1.480000e+07</td>\n",
       "      <td>1.000000e+08</td>\n",
       "      <td>2.070800e+07</td>\n",
       "      <td>4.000000e+07</td>\n",
       "      <td>1.040000e+07</td>\n",
       "      <td>3.196120e+08</td>\n",
       "      <td>6.000000e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>7.600000e+07</td>\n",
       "      <td>1.235880e+08</td>\n",
       "      <td>1.300000e+08</td>\n",
       "      <td>1.444000e+08</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>3.013120e+08</td>\n",
       "      <td>1.064200e+08</td>\n",
       "      <td>1.400000e+08</td>\n",
       "      <td>6.176800e+07</td>\n",
       "      <td>4.320000e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 4735 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          48df886f9     0deb4b6a8     34b15f335     a8cb14b00     2f0771a37  \\\n",
       "count  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean   1.465493e+04  1.390895e+03  2.672245e+04  4.530164e+03  2.640996e+04   \n",
       "std    3.893298e+05  6.428302e+04  5.699652e+05  2.359124e+05  1.514730e+06   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    2.000000e+07  4.000000e+06  2.000000e+07  1.480000e+07  1.000000e+08   \n",
       "\n",
       "          30347e683     d08d1fbe3     6ee66e115     20aa07010     dc5a8f1d8  \\\n",
       "count  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean   3.070811e+04  1.686522e+04  4.669208e+03  2.569407e+06  1.552158e+05   \n",
       "std    5.770590e+05  7.512756e+05  1.879449e+05  9.610183e+06  1.587815e+06   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  6.000000e+05  0.000000e+00   \n",
       "max    2.070800e+07  4.000000e+07  1.040000e+07  3.196120e+08  6.000000e+07   \n",
       "\n",
       "           ...          3ecc09859     9281abeea     8675bec0b     3a13ed79a  \\\n",
       "count      ...       4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean       ...       4.676057e+05  4.446239e+05  8.056219e+05  7.812966e+05   \n",
       "std        ...       4.068038e+06  4.428889e+06  4.513246e+06  6.839451e+06   \n",
       "min        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max        ...       7.600000e+07  1.235880e+08  1.300000e+08  1.444000e+08   \n",
       "\n",
       "           f677d4d13     71b203550     137efaa80     fb36b89d9     7e293fbaf  \\\n",
       "count    4459.000000  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean      143.529939  1.213809e+05  3.573451e+04  3.123741e+05  9.219960e+04   \n",
       "std      9584.318507  4.720709e+06  1.614622e+06  4.318501e+06  1.635993e+06   \n",
       "min         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    640000.000000  3.013120e+08  1.064200e+08  1.400000e+08  6.176800e+07   \n",
       "\n",
       "          9fc776466  \n",
       "count  4.459000e+03  \n",
       "mean   2.279100e+05  \n",
       "std    1.811139e+06  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    4.320000e+07  \n",
       "\n",
       "[8 rows x 4735 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some basic stats for the features\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Might consider using a different scaler\n",
    "\n",
    "#Fit and transform to train\n",
    "x = train_df.values\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "scaled_train_df = pd.DataFrame(x_scaled, columns=train_df.columns)\n",
    "\n",
    "#Transform test\n",
    "x = test_df.values\n",
    "x_scaled = scaler.transform(x)\n",
    "scaled_test_df = pd.DataFrame(x_scaled, columns=test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>dc5a8f1d8</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.008039</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006153</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.005276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.019466</td>\n",
       "      <td>0.016071</td>\n",
       "      <td>0.028498</td>\n",
       "      <td>0.015940</td>\n",
       "      <td>0.015147</td>\n",
       "      <td>0.027866</td>\n",
       "      <td>0.018782</td>\n",
       "      <td>0.018072</td>\n",
       "      <td>0.030068</td>\n",
       "      <td>0.026464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053527</td>\n",
       "      <td>0.035836</td>\n",
       "      <td>0.034717</td>\n",
       "      <td>0.047365</td>\n",
       "      <td>0.014975</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.015172</td>\n",
       "      <td>0.030846</td>\n",
       "      <td>0.026486</td>\n",
       "      <td>0.041925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 4735 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         48df886f9    0deb4b6a8    34b15f335    a8cb14b00    2f0771a37  \\\n",
       "count  4459.000000  4459.000000  4459.000000  4459.000000  4459.000000   \n",
       "mean      0.000733     0.000348     0.001336     0.000306     0.000264   \n",
       "std       0.019466     0.016071     0.028498     0.015940     0.015147   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "         30347e683    d08d1fbe3    6ee66e115    20aa07010    dc5a8f1d8  \\\n",
       "count  4459.000000  4459.000000  4459.000000  4459.000000  4459.000000   \n",
       "mean      0.001483     0.000422     0.000449     0.008039     0.002587   \n",
       "std       0.027866     0.018782     0.018072     0.030068     0.026464   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.001877     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          ...         3ecc09859    9281abeea    8675bec0b    3a13ed79a  \\\n",
       "count     ...       4459.000000  4459.000000  4459.000000  4459.000000   \n",
       "mean      ...          0.006153     0.003598     0.006197     0.005411   \n",
       "std       ...          0.053527     0.035836     0.034717     0.047365   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "max       ...          1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "         f677d4d13    71b203550    137efaa80    fb36b89d9    7e293fbaf  \\\n",
       "count  4459.000000  4459.000000  4459.000000  4459.000000  4459.000000   \n",
       "mean      0.000224     0.000403     0.000336     0.002231     0.001493   \n",
       "std       0.014975     0.015667     0.015172     0.030846     0.026486   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "         9fc776466  \n",
       "count  4459.000000  \n",
       "mean      0.005276  \n",
       "std       0.041925  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 4735 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for duplicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4459, 4735)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4459, 4692)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodups_train_df = scaled_train_df.T.drop_duplicates().T\n",
    "nodups_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_columns = [col for col in scaled_test_df.columns if col not in nodups_train_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49342, 4735)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for correlation of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "pca_train = pca.fit_transform(scaled_train_df)\n",
    "pca_test = pca.transform(scaled_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some notes:\n",
    "\n",
    "DONE - CAN BE IMPROVED - Quite a few features have constant values in the train set, but not in the test set. For now, they are completely removed, but is there a better way to take advantage of this? Maybe not deleting them is better? <br>\n",
    "DONE - CAN BE IMPROVED - The value ranges for the features are not the same. A scaler is used to put all the features in the same range. Different types of scalers should be compared here. <br>\n",
    "TO DO - Check for duplicate columns in train and test. Seems pandas has a built-in function. <br>\n",
    "TO DO - High number of dimensions compared to dataset size. Should probably perform some kind of dimensionality reduction to get rid of some, seamingly, useless features. Maybe PCA or some other technique. Refer to some kernel for more information. <br>\n",
    "\"In practice, TruncatedSVD is very useful for highly sparse datasets which cannot be centered without making the memory usage explode.\": https://www.kaggle.com/ishaan45/lgbm-with-tsvd <br>\n",
    "TO DO - Maybe some sort of exploration for each of the features should be made. Or at least, the most important features should be found according to some model. <br>\n",
    "TO DO - Some feature engineering might be possible? E.g. sum of zeros, or sum of values in a given row. <br>\n",
    "Also, using KMeans clustering to add new features: https://www.kaggle.com/samratp/aggregates-sumvalues-sumzeros-k-means-pca <br>\n",
    "TO DO - Most values are low values. In other words, target is heavily skewed. Needs to be looked into. <br>\n",
    "TO DO - Test size is a lot bigger than the train. This could suggest a semi-supervised approach should be considered. <br>\n",
    "TO DO - Train test split to build a validation set. KFold Cross validation might also be useful here (and quite doable since the dataset is not that big).\n",
    "TO DO - Choose a model that is suited for the problem at hand. <br>\n",
    "\"LGBM is a new powerful alternative to XGBoost. It is gradient boosting machine which focuses on leaf wise tree growth rather than level wise tree growth which ensures fast learning and high accuracy. It is quiet difficult to train LGBM because there are huge number of parameters so it is advised to at least \n",
    "work on some core parameters while training your model.\": https://www.kaggle.com/ishaan45/lgbm-with-tsvd <br>\n",
    "TO DO - Choose more than one model, and take an average/weighted average of the predictions. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(pca_train)\n",
    "y_train = np.array(np.log1p(y_train))\n",
    "\n",
    "x_test = np.array(pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 30,\n",
    "        \"learning_rate\" : 0.01,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.7,\n",
    "        \"bagging_frequency\" : 5,\n",
    "        \"bagging_seed\" : 2018,\n",
    "        \"verbosity\" : -1\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgbm.Dataset(train_X, label=train_y)\n",
    "    lgval = lgbm.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgbm.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=200, evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.50479\n",
      "[400]\tvalid_0's rmse: 1.48857\n",
      "[600]\tvalid_0's rmse: 1.48559\n",
      "Early stopping, best iteration is:\n",
      "[678]\tvalid_0's rmse: 1.48477\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.54972\n",
      "[400]\tvalid_0's rmse: 1.52906\n",
      "[600]\tvalid_0's rmse: 1.52561\n",
      "Early stopping, best iteration is:\n",
      "[618]\tvalid_0's rmse: 1.52494\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.55593\n",
      "[400]\tvalid_0's rmse: 1.53587\n",
      "[600]\tvalid_0's rmse: 1.52757\n",
      "[800]\tvalid_0's rmse: 1.52485\n",
      "Early stopping, best iteration is:\n",
      "[798]\tvalid_0's rmse: 1.52469\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.58837\n",
      "[400]\tvalid_0's rmse: 1.57571\n",
      "Early stopping, best iteration is:\n",
      "[383]\tvalid_0's rmse: 1.5751\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.54834\n",
      "[400]\tvalid_0's rmse: 1.52657\n",
      "[600]\tvalid_0's rmse: 1.52148\n",
      "Early stopping, best iteration is:\n",
      "[566]\tvalid_0's rmse: 1.52134\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "pred_test_full = 0\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    pred_test, model, evals_result = run_lgb(x_train[train_index], y_train[train_index], x_train[test_index], y_train[test_index], x_test)\n",
    "    pred_test_full += pred_test\n",
    "pred_test_full /= 5.\n",
    "pred_test_full = np.expm1(pred_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=10)\n",
    "kf = KFold(n_splits=10)\n",
    "rmsle = []\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    m.fit(x_train[train_index], y_train[train_index])\n",
    "    val_pred = m.predict(x_train[test_index])\n",
    "    rmsle.append(np.sqrt(mean_squared_log_error(y_test[test_index], val_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('y_pred.csv', 'w')\n",
    "f.write(\"ID,target\\n\")\n",
    "\n",
    "for idn, pred in zip(test_IDs, pred_test_full):\n",
    "    f.write(\"{},{}\\n\".format(idn, pred))\n",
    "f.flush()\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
